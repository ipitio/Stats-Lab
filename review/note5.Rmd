---
title: "AMS394_note5"
author: "Weihao Wang"
output:
  html_document: default
  pdf_document: default
---

**Analysis of variance: ANOVA**

**1. One way analysis of variance**

In this section, we consider comparisons among more than two groups parametrically, using analysis of variance.

Example 1:
```{r}
y1 <- c(18.2, 20.1, 17.6, 16.8, 18.8, 19.3, 19.1) 
y2 <- c(17.4, 18.7, 19.1, 16.4, 15.2, 18.4)
y3 <- c(15.2, 18.8, 17.7, 16.5, 15.9, 17.1, 16.3) 
y<-c(y1, y2, y3)
n<-c(7, 6, 7)
group<-c(rep(1,7), rep(2,6), rep(3,7))
ydata<-data.frame(y=y, group=factor(group)) 
str(ydata)
fit<-lm(y~group, ydata)
anova(fit)
# H0: all group means are the same
# p-value > .05 ==> cannot reject H0
```

Example 2:
```{r}
library(ISwR)
data(red.cell.folate)
attach(red.cell.folate)
summary(red.cell.folate)
# H0: the mean folate of different ventilation levels are the same
anova(lm(folate~ventilation))
mean(red.cell.folate[1:8,1])
mean(red.cell.folate[9:17,1])
mean(red.cell.folate[18:22,1])
```

The specification of a one-way analysis of variance is analogous to a regression analysis. The only difference is that the descriptive variable needs to be a factor and not a numeric variable. We calculate a model object using lm and extract the analysis of variance table with anova.

Example 3:
```{r}
data(juul)
attach(juul)
juul[1:20,]
anova(lm(igf1~tanner)) #this is wrong,
#This does not describe a grouping of data but a linear regression on the group number. Notice the telltale 1 DF for the effect of tanner.
juul$tanner<- factor(juul$tanner,labels=c("one","two","three","four","five"))
detach(juul)
attach(juul)
summary(tanner)
anova(lm(igf1~tanner))
```

1.1 Pairwise comparisons and multiple testing

```{r}
summary(lm(folate~ventilation))
```

These coefficients do not have their usual meaning as the slope of a regression line but have a special interpretation:
The interpretation of the estimates is that the intercept is the mean in the first group(N20+02,24h), whereas the other two describe the difference between the relevant group and the first group.
```{r}
mean(red.cell.folate[1:8,1])
mean(red.cell.folate[9:17,1])
mean(red.cell.folate[18:22,1])
```

ANOVA: H0: mu1 = mu2 = mu3
Piared comparison: H0: mu1 = mu2; mu1 = mu3; mu2 = mu3

Among the t tests in the table, you can immediately find a test for the hypothesis that the first two groups have the same true mean(p=0.0139) and also whether the first and the third might be identical (p=0.1548). However, a comparison of the last two groups cannot be found.

A function called pairwise.t.test computes all possible two-group comparisons:
```{r}
pairwise.t.test(folate,ventilation,p.adj="bonferroni") 
pairwise.t.test(folate,ventilation)
```

1.2 relaxing the variance assumption

The traditional one way ANOVA requires an assumption of equal variances for all groups.
```{r}
sd(red.cell.folate[1:8,1]) 
sd(red.cell.folate[9:17,1]) 
sd(red.cell.folate[18:22,1])
oneway.test(folate~ventilation) # compared with anova(lm(folate~ventilation))
# In this case the p-value increased to a nonsignificant value 0.09277.
pairwise.t.test(folate,ventilation,pool.sd=F)
```

1.3 graphical presentation

```{r}
xbar<-tapply(folate,ventilation,mean) 
s<-tapply(folate,ventilation,sd) 
n<-tapply(folate,ventilation,length)
sem<-s/sqrt(n)
stripchart(folate~ventilation,vert=T,pch=16 ,method="jitter") 
arrows(1:3,xbar+sem,1:3,xbar-sem,angle=90,code=3,length=0.1) 
lines(1:3,xbar,pch=4,type="b",cex=2)
```

1.4 bartlett’s test

```{r}
bartlett.test(folate~ventilation)
```

In this case, nothing id data contradicts the assumption of equal variances in the three groups.
Barlett’s test, although like the F test for comparison of two variances, it is rather nonrobust against departures from the assumption of normal distribution.

#We are often interested in determining whether the means from more than two populations or groups are equal or not. To test whether the
difference in means is statistically significant, we can perform analysis of variance (ANOVA) using the R function aov(). If the ANOV AF-test shows there is a significant difference in means between the
groups we may want to perform multiple comparisons between all pair -wise means to determine how they differ.
 
1.5  Examples of Analysis of Variance

The first step in our analysis is to graphically compare the means of the variable of interest across groups. It is possible to create side-by-side boxplots of measurements organized in groups using the function plot(). Simply type plot(response ~ factor, data=data_name )

where response is the name of the response variable and factor the variable that separates the data into groups. Both variables should be contained in a data frame called data_name.

Ex1. A drug company tested three formulations of a pain relief medicine for migraine headache sufferers. For the experiment 27 volunteer s were selected and 9 were randomly assigned to one of three drug formulations. The subjects were instructed to take the drug during t heir next migraine headache episode and to report their pain on a scale of 1 to 10 (10 being most pain).

Data:
Drug A 4 5 4 3 2 4 3 4 4 
Drug B 6 8 4 5 4 6 5 8 6
Drug C 6 7 6 6 7 5 6 5 5

To make side-by-side boxplots of the variable pain grouped by the variable drug we must first read in the data into the appropriate format.
```{r}
pain = c(4, 5, 4, 3, 2, 4, 3, 4, 4, 6, 8, 4, 5, 4, 6, 5, 8, 6, 6, 7, 6, 6, 7, 5, 6, 5, 5)
drug = c(rep("A",9), rep("B",9), rep("C",9)) 
migraine = data.frame(pain,drug);migraine
#Note the command rep("A",9) constructs a list of nine As in a row. The variable drug is therefore a list of length 27 consisting of nine As followed by nine Bs followed by nine Cs. If we print the data frame migraine we can see the format the data should be on in order to make side-by-side boxplots and perform ANOVA (note the output is cut-off between observations 6-25 for space purposes).
#We can now make the boxplots by typing:
boxplot(pain ~ drug, data=migraine)
#From the boxplots it appears that the mean pain for drug A is lower than that for drugs B and C.
#Next, the R function aov() can be used for fitting ANOVA models. The general form is aov(response ~ factor, data=data_name) where response represents the response variable and factor the varia ble that separates the data into groups. Both variables should be contained in the data frame called data_name. Once the ANOVA model is fit, one can look at the results using the summary() function. This produces the standard ANOVA table.

#Ex. Drug company example continued.
results = aov(pain ~ drug, data=migraine) #anova(lm(pain~drug, data=migraine))
summary(results)

#The results state that the difference in means is not significantly different between drugs B and C (p-value = 1.00), but both are significantly different from drug A (p-values = 0.00119 and 0.00068, res pectively). Hence, we can conclude that the mean pain is significantly different for drug A. Another multiple comparisons procedure is Tukey‟s method (a.k.a. Tukey's Honest Significance #Test).

#The function TukeyHSD() creates a set of confidence intervals on the differences between means with the specified family-wise probability of coverage. The general form is TukeyHSD(x, conf.level = 0.95) Here x is a fitted model object (e.g., an aov fit) and conf.level is the confidence level.
#Ex.Drug company example continued.
results = aov(pain ~ drug, data=migraine) 
TukeyHSD(results, conf.level = 0.95)
#These results show that the B-A and C-A differences are significant (p=0.0011 and p=0.00065, respectively), while the C-B difference is not (p=0.97). This confirms the results obtained using Bonferroni co rrection.
#Graphical display:to plot CIs from Tukey:
plot(TukeyHSD(results, conf.level = 0.95))
```

Pairwise test:
1. pairwise.t.test() with bonferroni
2. tukey test TukeyHSD()

**2. Two-way ANOVA**

```{r}
data(heart.rate)
attach(heart.rate)
heart.rate

heart.rate <- data.frame(hr = c(96,110,89,95,128,100,72,79,100, 92,106,86,78,124,98,68,75,106,86,108,85,78,118,100,67,74, 104, 92,114,83,83,118,94,71,74,102), subj=gl(9,1,36), time=gl(4,9,36,labels=c(0,30,60,120)))
```

The gl (generate levels) function is specially designed for generating patterned factors for balanced experimental designs. It has three arguments: the number of levels, the block length (how many times each level should repeat), and the total length of the result. The two patterns in the data frame are thus
```{r}
gl(9,1,36)
gl(4,9,36,labels=c(0,30,60,120))
```


```{r}
attach(heart.rate)
anova(lm(hr~subj+time))
```

2.1 graphics for repeated measurements

```{r}
interaction.plot(time,subj,hr)
```

2.2 ANOVA table in the regression analysis

```{r}
data(thuesen)
attach(thuesen) 
lm.velo<-lm(short.velocity~blood.glucose) 
summary(lm.velo)
anova(lm.velo)
```

Notice that the F test gives the same p-value as the t test for a zero slope. It is the same F test that gets printed at the end of the summary output Residual standard error is the square root of residual mean squares, namely 0.2167=sqrt(0.04696). R^2 is the proportion of the total sum of squares explained by the regression line, that is 0.1737=0.2073/(0.2073+0.9861)
```{r}
logret<- read.table("d_logret_6stocks.txt", header=T) 
attach(logret)
fit1<-lm(Pfizer~Intel)
anova(fit1)
fit2<-lm(Pfizer~Intel+AmerExp)
anova(fit2)
```

